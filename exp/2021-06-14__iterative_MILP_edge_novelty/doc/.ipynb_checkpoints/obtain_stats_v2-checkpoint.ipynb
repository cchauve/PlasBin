{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vanilla-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def update_dict(line, stat_dict, file, folder_loc):\n",
    "    stat = line.split(\" \")[-1]\n",
    "    stat_dict[file.split('/')[folder_loc]].append(float(stat))\n",
    "    return stat_dict\n",
    "\n",
    "def compute_mean(mean, k, precs, recs, f1s):\n",
    "    mean[k] = {}\n",
    "    mean[k]['precision'] = sum(precs[k])/len(precs[k])\n",
    "    mean[k]['recall'] = sum(recs[k])/len(recs[k])\n",
    "    mean[k]['f1_score'] = sum(f1s[k])/len(f1s[k])\n",
    "    return mean\n",
    "\n",
    "def compute_max(best, k, precs, recs, f1s):\n",
    "    best[k] = {}\n",
    "    best[k]['precision'] = max(precs[k])\n",
    "    best[k]['recall'] = max(recs[k])\n",
    "    best[k]['f1_score'] = max(f1s[k])\n",
    "    return best\n",
    "\n",
    "def get_output_details(output_dir):\n",
    "    files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(output_dir) for f in filenames if \"MILP_eval.csv\" in f]\n",
    "    precs, recs, f1s = defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "    prec_ratio, rec_ratio, f1_ratio = defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "\n",
    "    for file in files:\n",
    "        if 'sample' in file.split('/')[2]:\n",
    "            sample_id = file.split('/')[2].split('_')[1]\n",
    "            ratio = file.split('/')[3]\n",
    "            with open(file, 'r') as f:\n",
    "                for line in f:\n",
    "                    if \"precision\" in line:\n",
    "                        precs = update_dict(line, precs, file, 2)\n",
    "                        prec_ratio = update_dict(line, prec_ratio, file, 3)\n",
    "                    if \"recall\" in line:\n",
    "                        recs = update_dict(line, recs, file, 2)\n",
    "                        rec_ratio = update_dict(line, rec_ratio, file, 3)\n",
    "                    if \"f1\" in line:\n",
    "                        f1s = update_dict(line, f1s, file, 2)\n",
    "                        f1_ratio = update_dict(line, f1_ratio, file, 3)\n",
    "    return precs, recs, f1s, prec_ratio, rec_ratio, f1_ratio                    \n",
    "\n",
    "def get_mean(precs, recs, f1s):\n",
    "    mean, best = {}, {}\n",
    "    mean_scores, best_scores = [], [] \n",
    "    for sample_id in precs:\n",
    "        mean[sample_id] = {}\n",
    "        mean[sample_id]['precision'] = sum(precs[sample_id])/len(precs[sample_id])\n",
    "        mean[sample_id]['recall'] = sum(recs[sample_id])/len(recs[sample_id])\n",
    "        mean[sample_id]['f1_score'] = sum(f1s[sample_id])/len(f1s[sample_id])\n",
    "        mean_scores.append([sample_id, mean[sample_id]['precision'], mean[sample_id]['recall'], mean[sample_id]['f1_score']])\n",
    "\n",
    "        best[sample_id] = {}\n",
    "        best[sample_id]['precision'] = max(precs[sample_id])\n",
    "        best[sample_id]['recall'] = max(recs[sample_id])\n",
    "        best[sample_id]['f1_score'] = max(f1s[sample_id])  \n",
    "        best_scores.append([sample_id, best[sample_id]['precision'], best[sample_id]['recall'], best[sample_id]['f1_score']])\n",
    "\n",
    "    mean_scores = pd.DataFrame(mean_scores)\n",
    "    mean_scores.rename(columns = {0: 'Sample', 1: 'Precision', 2: 'Recall', 3: 'F1 score'}, inplace = True)\n",
    "\n",
    "    best_scores = pd.DataFrame(best_scores)\n",
    "    best_scores.rename(columns = {0: 'Sample', 1: 'Precision', 2: 'Recall', 3: 'F1 score'}, inplace = True)\n",
    "    return mean, best, mean_scores, best_scores\n",
    "\n",
    "def get_greedy_stats(greedy_dir, ids):\n",
    "    greedy_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(greedy_dir) for f in filenames if \"greedy_mean.csv\" in f]\n",
    "    greedy_precs, greedy_recs, greedy_f1s = defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "\n",
    "    count = {}\n",
    "    for file in greedy_files:\n",
    "        #print(file)\n",
    "        if file.split('/')[2] in ids:\n",
    "            with open(file, 'r') as f:\n",
    "                rl, pl, fl = [], [], []\n",
    "                for line in f:\n",
    "                    if \"score_ref_coverage\" in line:\n",
    "                        rl.append(line)\n",
    "                    if \"score_pred_coverage\" in line:\n",
    "                        pl.append(line)\n",
    "                    if \"overall_score\" in line:\n",
    "                        fl.append(line)       \n",
    "                greedy_recs = update_dict(rl[0], greedy_recs, file, 2)\n",
    "                greedy_precs = update_dict(pl[0], greedy_precs, file, 2)\n",
    "                greedy_f1s = update_dict(fl[0], greedy_f1s, file, 2)\n",
    "    return greedy_precs, greedy_recs, greedy_f1s            \n",
    "\n",
    "def get_ilp_stats(ilp_dir):\n",
    "    ilp_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(ilp_dir) for f in filenames if \"eval.csv\" in f]\n",
    "    ilp_precs, ilp_recs, ilp_f1s = defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "\n",
    "    for file in ilp_files:\n",
    "        if 'sample' in file.split('/')[4]:\n",
    "            sample_id = file.split('/')[4].split('_')[1]\n",
    "            ratio = file.split('/')[3]\n",
    "            with open(file, 'r') as f:\n",
    "                for line in f:\n",
    "                    if \"precision\" in line:\n",
    "                        ilp_precs = update_dict(line, ilp_precs, file, 2)\n",
    "                    if \"recall\" in line:\n",
    "                        ilp_recs = update_dict(line, ilp_recs, file, 2)\n",
    "                    if \"f1\" in line:\n",
    "                        ilp_f1s = update_dict(line, ilp_f1s, file, 2)\n",
    "    return ilp_precs, ilp_recs, ilp_f1s                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-eugene",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
